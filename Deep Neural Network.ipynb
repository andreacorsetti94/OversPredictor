{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from CustomPreProcessor import CustomPreProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing the Custom Pre Processor module, so that it loads the csv and elaborates the new dataset, the scaled inputs\n",
    "and the targets\n",
    "\"\"\"\n",
    "PP = CustomPreProcessor('dataset.csv')\n",
    "dataset_preprocessed, scaled_inputs, targets = PP.pre_process(3, StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We split the data in 3 parts:\n",
    "- 80% : Training data\n",
    "- 10% : Validation Data\n",
    "- 10% : Testing Data\n",
    "\"\"\"\n",
    "train_data, validation_data, test_data = np.split(dataset_preprocessed, [int(.8 * len(dataset_preprocessed)), int(.9 * len(dataset_preprocessed))])\n",
    "\n",
    "train_data_inputs, train_data_targets = train_data.iloc[:,:-1], train_data.iloc[:,[-1]]\n",
    "validation_data_inputs, validation_data_targets = validation_data.iloc[:,:-1], validation_data.iloc[:,[-1]]\n",
    "test_data_inputs, test_data_targets = test_data.iloc[:,:-1], test_data.iloc[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We convert the pandas object into numpy objects, in order to feed them into the model\n",
    "\"\"\"\n",
    "np_train_data = train_data.to_numpy()\n",
    "np_val_inputs = validation_data_inputs.to_numpy()\n",
    "np_val_targets = validation_data_targets.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the maximum number of epochs\n",
    "NUM_EPOCHS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "After having specified the size of the inputs, the outputs and the hidden layers, we build the model sequentially\n",
    "\"\"\"\n",
    "input_size = 59\n",
    "output_size = 1\n",
    "\n",
    "hidden_layer_size = 75\n",
    "\n",
    "model = Sequential([\n",
    "            Dense(hidden_layer_size, input_shape=(input_size,)),\n",
    "            \n",
    "            Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
    "            Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
    "            Dense(hidden_layer_size, activation='relu'), # 3rd hidden layer\n",
    "            Dense(hidden_layer_size, activation='relu'), # 4th hidden layer\n",
    "            Dense(hidden_layer_size, activation='relu'), # 5th hidden layer\n",
    "    \n",
    "            Dense(output_size, activation='sigmoid') # output layer\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We compile the model using the well-known 'adam' optimizer and using the binary crossentropy loss function\n",
    "since the output has only 2 classes (0 and 1)\n",
    "\"\"\"\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 14808 samples, validate on 1851 samples\n",
      "Epoch 1/6\n",
      "14808/14808 - 7s - loss: 0.6875 - accuracy: 0.5387 - val_loss: 0.6873 - val_accuracy: 0.5429\n",
      "Epoch 2/6\n",
      "14808/14808 - 7s - loss: 0.6830 - accuracy: 0.5510 - val_loss: 0.6908 - val_accuracy: 0.5370\n",
      "Epoch 3/6\n",
      "14808/14808 - 9s - loss: 0.6820 - accuracy: 0.5577 - val_loss: 0.6889 - val_accuracy: 0.5402\n",
      "Epoch 4/6\n",
      "14808/14808 - 8s - loss: 0.6813 - accuracy: 0.5590 - val_loss: 0.6912 - val_accuracy: 0.5500\n",
      "Epoch 5/6\n",
      "14808/14808 - 9s - loss: 0.6798 - accuracy: 0.5652 - val_loss: 0.6881 - val_accuracy: 0.5359\n",
      "Epoch 6/6\n",
      "14808/14808 - 9s - loss: 0.6784 - accuracy: 0.5676 - val_loss: 0.6899 - val_accuracy: 0.5397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x264ae690508>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "We fit the model using the data extracted before and \n",
    "\"\"\"\n",
    "model.fit(x=train_data_inputs, y=train_data_targets, epochs=NUM_EPOCHS, validation_data=(np_val_inputs, np_val_targets), \n",
    "          validation_steps=len(np_val_inputs), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "1851/1851 - 0s - loss: 0.6838 - accuracy: 0.5586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.55861694"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing the model on the testing data\n",
    "\"\"\"\n",
    "loss_value, accuracy = model.evaluate(x=test_data_inputs, y=test_data_targets, verbose=2)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
